{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee869a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import time\n",
    "from git import Repo\n",
    "import os\n",
    "import sys\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import operator\n",
    "import random\n",
    "from scipy.stats import uniform\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn import decomposition, datasets\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "## Hyperparameter optimization using RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import xgboost\n",
    "\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    average_precision_score,\n",
    "    classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c87345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'dataset_rz'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "onlyfiles.remove('achilles.csv')\n",
    "onlyfiles.remove('sonar.csv')\n",
    "onlyfiles.remove('graylog2.csv')\n",
    "onlyfiles = ['ibm.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab84b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append-adds at last\n",
    "def append_file(output):\n",
    "    file1 = open(\"hp_apfd_outout_sota_default_FI_sep.txt\",\"a\")#append mode\n",
    "    file1.write(output +  \"\\n\")\n",
    "    file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4cd2d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_base_value ():\n",
    "    for file in onlyfiles:\n",
    "        append_file('base ' + file)\n",
    "        dataset = pd.read_csv('dataset_rz/' + file)\n",
    "        dataset = dataset.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "    \n",
    "        #print(file)\n",
    "        #append_file(file)\n",
    "        print(list(dataset))\n",
    "        #print(dataset.shape)\n",
    "        #append_file(str(dataset.shape[0]))\n",
    "        part = dataset.tail(int(dataset.shape[0] * 0.6))\n",
    "        append_file('data size ' + str(dataset.shape[0]))\n",
    "    \n",
    "    \n",
    "        column_names = [\"parent_job\", \"failure_array\", \"first_failure\", \"last_failure\", \"averag_failure_position\", \"APFD\"]\n",
    "        df_prob = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "        #dataset = pd.read_csv('prd_prob_' + date + clf.__class__.__name__+ 'tune_afp.csv')\n",
    "        dataset = part\n",
    "        #print(dataset)\n",
    "        #print(dataset.stage_id.unique())\n",
    "        parent_job_array = dataset.stage_id.unique()\n",
    "    \n",
    "        for parent_job in parent_job_array:\n",
    "            df = dataset[dataset['stage_id'] == parent_job]\n",
    "            n = len(df. index)\n",
    "            i = 1\n",
    "            failure_array = []\n",
    "        \n",
    "        \n",
    "            for a,b, c in zip(df.Test_Identifier, df['Failed'], df['stage_id']):\n",
    "                #print(a,b,c)\n",
    "                if (b == 1):\n",
    "                    #print(a,b,c)\n",
    "                    #print ('position', i)\n",
    "                    failure_array.append(i)\n",
    "                i+= 1\n",
    "                # m is the number of test suite failures.\n",
    "                m=len(failure_array)\n",
    "                if(m!=0):\n",
    "                    APFD=1-(sum(failure_array)/(m*n))+(1/(2*n))\n",
    "                    pj = c\n",
    "        \n",
    "            if(len(failure_array) > 0):\n",
    "                new_row = {'parent_job_name': c, 'parent_job': parent_job, 'failure_array': failure_array , 'first_failure': failure_array[0], \"last_failure\": failure_array[-1]  , \"averag_failure_position\": statistics.mean(failure_array), \"APFD\": APFD}\n",
    "                #append row to the dataframe\n",
    "                df_prob = df_prob.append(new_row, ignore_index=True)\n",
    "                \n",
    "    append_file('AFP Base (mean) of '+  + file + str(df_prob['averag_failure_position'].mean()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14aab93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = pd.read_csv('../data/ml_ready_data_2022_july.csv')\n",
    "def calcualte_afp_value (clf_new):\n",
    "    feature_importance_arrays = []\n",
    "    for file in onlyfiles:\n",
    "        append_file(file)\n",
    "        dataset = pd.read_csv('dataset_rz/' + file)\n",
    "        dataset = dataset.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "    \n",
    "        #print(file)\n",
    "        #append_file(file)\n",
    "        #print(list(dataset))\n",
    "        print(file, dataset.shape)\n",
    "        #append_file(str(dataset.shape[0]))\n",
    "        part = dataset.tail(int(dataset.shape[0] * 1))\n",
    "        append_file('data size ' + str(dataset.shape[0]))\n",
    "\n",
    "        \n",
    "        columns = [\n",
    "            'Test_Identifier',\n",
    "            'Execution_Count',\n",
    "            'Test_Total',\n",
    "            'Failure_Count', \n",
    "            'Failure_Rate', \n",
    "            'Last_Failure_Age', \n",
    "            'Last_Failure', \n",
    "            'Last_Transition', \n",
    "            'Transition_Count',\n",
    "            '#Files_Changed',\n",
    "            '#Lines_Inserted',\n",
    "            '#Lines_Deleted'\n",
    "        ]\n",
    "        \n",
    "        #columns = [\n",
    "        #    'Test_Identifier',\n",
    "        #    'Execution_Count',\n",
    "        #    'Test_Total',\n",
    "            \n",
    "            \n",
    "        #    'Last_Transition', \n",
    "        #    'Transition_Count',\n",
    "        #    '#Lines_Inserted',\n",
    "        #]\n",
    "    \n",
    "        X = part.drop('Failed', axis=1)\n",
    "        y = part['Failed']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=42, stratify=y)\n",
    "        #print(X_train, X_test, y_train, y_test)\n",
    "        X_test_all = X_test\n",
    "        X_train = X_train[columns]\n",
    "        #y_train=y_train['Failed']\n",
    "        X_test = X_test[columns]\n",
    "        #y_test = y_test['Failed']\n",
    "        \n",
    "        print('train size', X_train.shape[0]/X.shape[0])\n",
    "        print(y_train.value_counts())\n",
    "        print('test size', X_test.shape[0]/X.shape[0])\n",
    "        print(y_test.value_counts())\n",
    "        \n",
    "    \n",
    "        print(clf_new)\n",
    "        append_file(str(clf_new))\n",
    "        clf = clf_new\n",
    "        #print(clf.__class__.__name__)\n",
    "        append_file(clf.__class__.__name__)\n",
    "        start = time.time()\n",
    "        clf.fit(X_train,y_train)\n",
    "        stop = time.time()\n",
    "        append_file(\"Training time:\" + str((stop - start)) + \"s\")\n",
    "        pred = clf.predict_proba(X_test)\n",
    "    \n",
    "        y_pred = clf.predict(X_test)\n",
    "    \n",
    "        score = clf.score(X_test, y_test)\n",
    "        \n",
    "        print(clf.__class__.__name__)\n",
    "        \n",
    "        if clf.__class__.__name__ == 'RandomForestClassifier':\n",
    "            feature_names = [f\"feature {i}\" for i in range(X_train.shape[1])]\n",
    "            start_time = time.time()\n",
    "            importances = clf.feature_importances_\n",
    "            std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "        \n",
    "            feature_names = X_train.columns  # Use the actual feature names\n",
    "            \n",
    "            # Store feature importances in the array\n",
    "            feature_importance_arrays.append((feature_names, importances))\n",
    "    \n",
    "            forest_importances = pd.Series(importances, index=feature_names)\n",
    "            print(forest_importances)\n",
    "    \n",
    "            fig, ax = plt.subplots()\n",
    "            forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "            ax.set_title(\"Feature importances using MDI using \" + file)\n",
    "            ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "            fig.tight_layout()\n",
    "            plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "            plt.show()  # Display the plot\n",
    "            \n",
    "        if clf.__class__.__name__ == 'DecisionTreeClassifier':\n",
    "            # let's create a dictionary of features and their importance values\n",
    "            feat_dict= {}\n",
    "            for col, val in sorted(zip(X_train.columns, clf.feature_importances_),key=lambda x:x[1],reverse=True):\n",
    "                feat_dict[col]=val\n",
    "            feat_df = pd.DataFrame({'Feature':feat_dict.keys(),'Importance':feat_dict.values()})\n",
    "            print(feat_df)\n",
    "            \n",
    "        if clf.__class__.__name__ == 'XGBClassifier':\n",
    "            print(clf.feature_importances_)\n",
    "            sorted_idx = xgb.feature_importances_.argsort()\n",
    "            plt.barh(X_train.columns[sorted_idx], xgb.feature_importances_[sorted_idx])\n",
    "            plt.xlabel(\"Xgboost Feature Importance\")\n",
    "        if clf.__class__.__name__ == 'GradientBoostingClassifier':\n",
    "            imp_features = clf.feature_importances_\n",
    "            for i in imp_features:\n",
    "                print(i.round(3))\n",
    "                features = X_train.columns  # Use the actual feature names\n",
    "                df_imp_features = pd.DataFrame({\"features\":features}).join(pd.DataFrame({\"weights\":imp_features}))\n",
    "                df_imp_features.sort_values(by=['weights'], ascending=False)\n",
    "                print(df_imp_features)\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "        print('Accuracy', accuracy_score(y_test, y_pred))\n",
    "        append_file('Accuracy')\n",
    "        append_file(str(accuracy_score(y_test, y_pred)))\n",
    "        print('balanced_accuracy_score', balanced_accuracy_score(y_test, y_pred))\n",
    "        print('AUC', roc_auc_score(y_test, y_pred))\n",
    "        append_file('AUC')\n",
    "        append_file(str(roc_auc_score(y_test, y_pred)))\n",
    "    \n",
    "        append_file(classification_report(y_test,y_pred, target_names=['Passed tests', 'Failed tests'], digits=4))\n",
    "        print(classification_report(y_test,y_pred, target_names=['Passed tests', 'Failed tests'], digits=4))\n",
    "        \n",
    "        if file == 'ibm.csv':\n",
    "            parent_job = 'PARENT_JOB'\n",
    "        else:\n",
    "            parent_job = 'stage_id'\n",
    "    \n",
    "        submission = pd.DataFrame({\n",
    "            \"PARENT_JOB\":list(X_test_all[parent_job]),\n",
    "            \"BUCKET_Number\":list(X_test[\"Test_Identifier\"]),\n",
    "            \"y_actual\":list(y_test),\n",
    "            \"y_pred\":list(y_pred),\n",
    "            \"probabilities\":list(pred)\n",
    "        })\n",
    "    \n",
    "    \n",
    "        column_names = [\"parent_job\", \"failure_array\", \"failure_prob\", \"first_failure\", \"last_failure\", \"averag_failure_position\", \"APFD\"]\n",
    "        df_prob = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "        #dataset = pd.read_csv('prd_prob_' + date + clf.__class__.__name__+ 'tune_afp.csv')\n",
    "        dataset = submission\n",
    "        #print(dataset)\n",
    "        #print(dataset.PARENT_JOB.unique())\n",
    "        parent_job_array = dataset.PARENT_JOB.unique()\n",
    "    \n",
    "        for parent_job in parent_job_array:\n",
    "            #print(str(parent_job))\n",
    "            df = dataset[dataset['PARENT_JOB'] == parent_job]\n",
    "        \n",
    "            df['probabilities'] = df['probabilities'].str[-1:].astype(float)\n",
    "            #print(df['probabilities'])\n",
    "            df = df.sort_values(by=['probabilities'],ignore_index=True, ascending=False)\n",
    "            n = len(df. index)\n",
    "        \n",
    "            i = 1\n",
    "            failure_array = []\n",
    "            prob_position_array = []\n",
    "        \n",
    "            for a,b, c, d in zip(df.BUCKET_Number, df['y_actual'], df['y_pred'], df['probabilities']):\n",
    "                #print(a,b,c)\n",
    "                if (b == 1):\n",
    "                    #print(a,b,c)\n",
    "                    #print ('position', i)\n",
    "                    failure_array.append(i)\n",
    "                    prob_position_array.append(d)\n",
    "                i+= 1\n",
    "                # m is the number of test suite failures.\n",
    "                m=len(failure_array)\n",
    "                if(m!=0):\n",
    "                    APFD=1-(sum(failure_array)/(m*n))+(1/(2*n))\n",
    "        \n",
    "            if(len(failure_array) > 0):\n",
    "            \n",
    "                new_row = pd.DataFrame({'parent_job': parent_job,\n",
    "                                        'failure_array': failure_array,\n",
    "                                        'failure_prob': prob_position_array,\n",
    "                                        'first_failure': failure_array[0],\n",
    "                                        \"last_failure\": failure_array[-1]  ,\n",
    "                                        \"averag_failure_position\": statistics.mean(failure_array),\n",
    "                                        \"APFD\": APFD})\n",
    "                df_prob = pd.concat([df_prob, new_row])\n",
    "        \n",
    "            #import statistic as st\n",
    "        print('APFD (mean)', df_prob['APFD'].mean())\n",
    "        append_file('APFD (mean) '+ str(df_prob['APFD'].mean()))\n",
    "        append_file('first failure (mean) '+ str(df_prob['first_failure'].mean()))\n",
    "        append_file('last failure (mean) '+ str(df_prob['last_failure'].mean()))\n",
    "        append_file('AFP (mean) '+ str(df_prob['averag_failure_position'].mean()))\n",
    "        print('first failure (mean)', df_prob['first_failure'].mean())\n",
    "        print('last failure (mean)', df_prob['last_failure'].mean())\n",
    "        print('AFP (mean)', df_prob['averag_failure_position'].mean())\n",
    "        print('***************')\n",
    "        print(feature_importance_arrays)\n",
    "        #return df_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bc1457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hptune_task():\n",
    "    c = ''\n",
    "    avg_scores = {}\n",
    "    newDF = pd.DataFrame() #creates a new dataframe that's empty\n",
    "\n",
    "    random_forest= {\n",
    "#         'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            #'n_estimators': [1,10,20],\n",
    "            'n_estimators': [100],\n",
    "            #'criterion': [\"gini\", 'entropy'],\n",
    "            'criterion': [\"gini\"],\n",
    "            'max_features': ['sqrt'],\n",
    "            #'max_features': [None, 'sqrt', 'log2']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    decision_tree = {\n",
    "#         'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            #'max_depth': [2,6, 8,10],\n",
    "            'max_depth': [5],\n",
    "            #'criterion': ['gini', 'entropy'],\n",
    "            'criterion': ['gini'],\n",
    "            #'splitter': ['best', 'random'],\n",
    "            'splitter': ['best'],\n",
    "            #'max_features': ['auto', 'sqrt', 'log2']\n",
    "            'max_features': ['auto']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    XGBClassifier = {\n",
    "#         'model': XGBClassifier(),\n",
    "        'params': {\n",
    "#             'min_child_weight': [1, 5, 10],\n",
    "#             'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "             #'subsample': [0.6, 0.8, 1],\n",
    "             'subsample': [1],\n",
    "             #'eta': [0.1, 0.5, 0.3],\n",
    "             'eta': [0.3],\n",
    "#             'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "             #'max_depth': [2, 4, 10]\n",
    "             'max_depth': [6]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    gboostingClassifier = {\n",
    "#         'model': GradientBoostingClassifier(),\n",
    "        'params': {\n",
    "             #\"learning_rate\": [0.1, 0.5, 1],\n",
    "             \"learning_rate\": [0.1],\n",
    "#             \"subsample\"    : sp_randFloat(),\n",
    "             #\"n_estimators\" : [10, 20, 30],\n",
    "             \"n_estimators\" : [100],\n",
    "             #\"max_depth\"    : [4, 10]\n",
    "             \"max_depth\"    : [3]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(\"Which Machine Learning Classifier you want to optimized?\")\n",
    "    print(\"Press 1 - Decision tree, \\nPress 2 - Random Forest,\\nPress 3 - XGBoost,\\nPress 4 - Gradient Boosting,\\nPress 0 - All Models\\n\")\n",
    "    x = input(\"\")\n",
    "    # print(\"Hello, \" + x)\n",
    "\n",
    "    if x == \"1\":\n",
    "        print(\"Decision tree classifier selected\")\n",
    "        for q in decision_tree['params']['max_depth']:\n",
    "            for r in decision_tree['params']['criterion']:\n",
    "                for s in decision_tree['params']['splitter']:\n",
    "                    for t in decision_tree['params']['max_features']:\n",
    "                        df_probab = calcualte_afp_value(DecisionTreeClassifier(max_depth=q, criterion=r, splitter=s, max_features=t))\n",
    "                        #cv_scores = df_probab['averag_failure_position'].mean()\n",
    "                        #avg_scores['decision_tree_' + r + '_' + str(q)] = cv_scores\n",
    "                        #newDF['decision_tree_' + r + '_' + str(q)] =  df_probab['averag_failure_position']\n",
    "                \n",
    "    elif x == \"2\":\n",
    "        print(\"Random Forest classifier selected\")\n",
    "        for q in random_forest['params']['n_estimators']:\n",
    "            for r in random_forest['params']['criterion']:\n",
    "                for s in random_forest['params']['max_features']:\n",
    "                    df_probab = calcualte_afp_value(RandomForestClassifier(n_estimators=q, criterion=r, max_features=s))\n",
    "                    #df_probab = calcualte_afp_value(RandomForestClassifier())\n",
    "                    #cv_scores = df_probab['averag_failure_position'].mean()\n",
    "                    #avg_scores['random_forest' + '_n_estimators_' + str(q)] = cv_scores\n",
    "                    #newDF['random_forest' + '_n_estimators_' + str(q)] =  df_probab['averag_failure_position']\n",
    "        \n",
    "    elif x == \"3\":\n",
    "        print(\"Xgboost classifier selected\")\n",
    "        for q in XGBClassifier['params']['max_depth']:\n",
    "            for r in XGBClassifier['params']['eta']:\n",
    "                for s in XGBClassifier['params']['subsample']:\n",
    "                    df_probab = calcualte_afp_value(xgboost.XGBClassifier(max_depth=q, eta=r, subsample=s))\n",
    "                    #cv_scores = df_probab['averag_failure_position'].mean()\n",
    "                    #avg_scores['XGBClassifier' + '_max_depth_' + str(q)] = cv_scores\n",
    "                    #newDF['XGBClassifier' + '_max_depth_' + str(q)] =  df_probab['averag_failure_position']    \n",
    "    elif x == \"4\":\n",
    "        print(\"Gradient boosting classifier selected\")\n",
    "        for q in gboostingClassifier['params']['max_depth']:\n",
    "            for r in gboostingClassifier['params']['learning_rate']:\n",
    "                for s in gboostingClassifier['params']['n_estimators']:\n",
    "                    df_probab = calcualte_afp_value(GradientBoostingClassifier(max_depth=q, learning_rate=r, n_estimators=s))\n",
    "                    #cv_scores = df_probab['averag_failure_position'].mean()\n",
    "                    #avg_scores['GradientBoostingClassifier' + '_max_depth_' + str(q)] = cv_scores\n",
    "                    #newDF['GradientBoostingClassifier' + '_max_depth_' + str(q)] =  df_probab['averag_failure_position']\n",
    "    elif x == \"0\":\n",
    "        print(\"Decision tree classifier selected\")\n",
    "        for q in decision_tree['params']['max_depth']:\n",
    "            for r in decision_tree['params']['criterion']:\n",
    "                for s in decision_tree['params']['splitter']:\n",
    "                    for t in decision_tree['params']['max_features']:\n",
    "                        df_probab = calcualte_afp_value(DecisionTreeClassifier(max_depth=q, criterion=r, splitter=s, max_features=t))\n",
    "                        #cv_scores = df_probab['averag_failure_position'].mean()\n",
    "                        #avg_scores['decision_tree_' + r + '_' + str(q)] = cv_scores\n",
    "                        #newDF['decision_tree_' + r + '_' + str(q)] =  df_probab['averag_failure_position']\n",
    "            \n",
    "        print(\"Random Forest classifier selected\")\n",
    "        for q in random_forest['params']['n_estimators']:\n",
    "            for r in random_forest['params']['criterion']:\n",
    "                for s in random_forest['params']['max_features']:\n",
    "                    df_probab = calcualte_afp_value(RandomForestClassifier(n_estimators=q, criterion=r, max_features=s))\n",
    "                    #df_probab = calcualte_afp_value(RandomForestClassifier())\n",
    "                    #cv_scores = df_probab['averag_failure_position'].mean()\n",
    "                    #avg_scores['random_forest' + '_n_estimators_' + str(q)] = cv_scores\n",
    "                    #newDF['random_forest' + '_n_estimators_' + str(q)] =  df_probab['averag_failure_position']\n",
    "    \n",
    "        print(\"Xgboost classifier selected\")\n",
    "        for q in XGBClassifier['params']['max_depth']:\n",
    "            for r in XGBClassifier['params']['eta']:\n",
    "                for s in XGBClassifier['params']['subsample']:\n",
    "                    df_probab = calcualte_afp_value(xgboost.XGBClassifier(max_depth=q, eta=r, subsample=s))\n",
    "                    #cv_scores = df_probab['averag_failure_position'].mean()\n",
    "                    #avg_scores['XGBClassifier' + '_max_depth_' + str(q)] = cv_scores\n",
    "                    #newDF['XGBClassifier' + '_max_depth_' + str(q)] =  df_probab['averag_failure_position']    \n",
    "        print(\"Gradient boosting classifier selected\")\n",
    "        for q in gboostingClassifier['params']['max_depth']:\n",
    "            for r in gboostingClassifier['params']['learning_rate']:\n",
    "                for s in gboostingClassifier['params']['n_estimators']:\n",
    "                    df_probab = calcualte_afp_value(GradientBoostingClassifier(max_depth=q, learning_rate=r, n_estimators=s))\n",
    "                    #cv_scores = df_probab['averag_failure_position'].mean()\n",
    "                    #avg_scores['GradientBoostingClassifier' + '_max_depth_' + str(q)] = cv_scores\n",
    "                    #newDF['GradientBoostingClassifier' + '_max_depth_' + str(q)] =  df_probab['averag_failure_position']\n",
    "        \n",
    "    else: \n",
    "        \"Invalid input\"\n",
    "    \n",
    "    #print(avg_scores)\n",
    "    #best_ml = min(avg_scores.items(), key=operator.itemgetter(1))[0]\n",
    "    #print(min(avg_scores.items(), key=operator.itemgetter(1))[0])\n",
    "    #base_df = calcualte_base_value()\n",
    "    #print(base_df)\n",
    "    #append_file('base_apfd ' + str(base_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a361b0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which Machine Learning Classifier you want to optimized?\n",
      "Press 1 - Decision tree, \n",
      "Press 2 - Random Forest,\n",
      "Press 3 - XGBoost,\n",
      "Press 4 - Gradient Boosting,\n",
      "Press 0 - All Models\n",
      "\n",
      "2\n",
      "Random Forest classifier selected\n",
      "ibm.csv (4571562, 26)\n",
      "train size 0.5999999562512769\n",
      "0    2732387\n",
      "1      10550\n",
      "Name: Failed, dtype: int64\n",
      "test size 0.4000000437487231\n",
      "0    1821592\n",
      "1       7033\n",
      "Name: Failed, dtype: int64\n",
      "RandomForestClassifier(max_features='sqrt')\n",
      "RandomForestClassifier\n",
      "Elapsed time to compute the importances: 0.031 seconds\n",
      "Test_Identifier     0.106354\n",
      "Execution_Count     0.127713\n",
      "Test_Total          0.124377\n",
      "Failure_Count       0.063095\n",
      "Failure_Rate        0.113720\n",
      "Last_Failure_Age    0.092665\n",
      "Last_Failure        0.077347\n",
      "Last_Transition     0.077746\n",
      "Transition_Count    0.066203\n",
      "#Files_Changed      0.040077\n",
      "#Lines_Inserted     0.060791\n",
      "#Lines_Deleted      0.049911\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9981986465240276\n",
      "balanced_accuracy_score 0.7949248661037038\n",
      "AUC 0.7949248661037038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Passed tests     0.9984    0.9998    0.9991   1821592\n",
      "Failed tests     0.9099    0.5901    0.7159      7033\n",
      "\n",
      "    accuracy                         0.9982   1828625\n",
      "   macro avg     0.9542    0.7949    0.8575   1828625\n",
      "weighted avg     0.9981    0.9982    0.9980   1828625\n",
      "\n",
      "APFD (mean) 0.9137902947173085\n",
      "first failure (mean) 9.962036115455708\n",
      "last failure (mean) 58.670553106782315\n",
      "AFP (mean) 27.13322906298885\n",
      "***************\n",
      "[(Index(['Test_Identifier', 'Execution_Count', 'Test_Total', 'Failure_Count',\n",
      "       'Failure_Rate', 'Last_Failure_Age', 'Last_Failure', 'Last_Transition',\n",
      "       'Transition_Count', '#Files_Changed', '#Lines_Inserted',\n",
      "       '#Lines_Deleted'],\n",
      "      dtype='object'), array([0.10635441, 0.12771255, 0.12437685, 0.06309517, 0.11372   ,\n",
      "       0.09266548, 0.07734697, 0.07774597, 0.06620334, 0.04007707,\n",
      "       0.06079074, 0.04991144]))]\n"
     ]
    }
   ],
   "source": [
    "hptune_task()\n",
    "#calcualte_base_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6101a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d40e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the first column\n",
    "#cols = [0]\n",
    "#dataset.drop(dataset.columns[cols],axis=1,inplace=True)\n",
    "#dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f00f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61875c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['JOB_START_TIMESTAMP'] = pd.to_datetime(dataset['JOB_START_TIMESTAMP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c7a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['JOB_START_TIMESTAMP'].dt.date.astype(str) < '2020-01-01']\n",
    "dataset = dataset.sort_values(by=['JOB_START_TIMESTAMP'],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44abfbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ea9cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date = '2019-10-01'\n",
    "\n",
    "train = dataset[dataset['JOB_START_TIMESTAMP'].dt.date.astype(str) < date]\n",
    "test = dataset[dataset['JOB_START_TIMESTAMP'].dt.date.astype(str) >= date]\n",
    "\n",
    "print('train size', train.shape[0]/dataset.shape[0])\n",
    "print('test size', test.shape[0]/dataset.shape[0])\n",
    "#test.to_csv('original_test_build.csv')\n",
    "# print(train)\n",
    "print('**********')\n",
    "print(dataset.PARENT_JOB.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6db6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['match_count', 'BUCKET_NAME','TEST_TOTAL','#Files changed','#Lines Deleted','#Lines Inserted','contains_unit','contains_fat','contains_java_filetype']\n",
    "X_train = train[columns]\n",
    "y_train=train['FAILED']\n",
    "X_test = test[columns]\n",
    "y_test = test['FAILED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78828b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_met = 'f1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import sklearn.metrics\n",
    "\n",
    "print(sorted(sklearn.metrics.SCORERS.keys()))\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "# param_dist = {\"max_depth\": [3, None],\n",
    "#               \"max_features\": randint(1, 9),\n",
    "#               \"min_samples_leaf\": randint(1, 9),\n",
    "#               \"criterion\": [\"gini\", \"entropy\"]}\n",
    "param_dist = {'max_depth': [2,4,5, 6, 7, 8,10,12, 25, 50, 100,500],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5, scoring=scoring_met)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X_train,y_train)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))\n",
    "\n",
    "append_file(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed448a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Hyperparameter optimization using RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import xgboost\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "        #'min_child_weight': [1, 5, 10],\n",
    "        #'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        #'subsample': [0.6, 0.8, 1.0],\n",
    "        #'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5, 10, 50, 100, 500]\n",
    "        }\n",
    "\n",
    "classifier=xgboost.XGBClassifier()\n",
    "random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring=scoring_met,n_jobs=-1,cv=5,verbose=3)\n",
    "random_search.fit(X_train,y_train)\n",
    "\n",
    "print(random_search.best_estimator_)\n",
    "print(random_search.best_params_)\n",
    "\n",
    "append_file(\"Tuned xgboost Parameters: {}\".format(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40679796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    #\"learning_rate\": sp_randFloat(),\n",
    "    #\"subsample\"    : sp_randFloat(),\n",
    "    #\"n_estimators\" : sp_randInt(100, 1000),\n",
    "    \"max_depth\"    : [4, 6, 8, 10, 25, 50, 100, 500]\n",
    "}\n",
    "\n",
    "randm = RandomizedSearchCV(estimator=model, param_distributions = parameters,cv = 2, n_iter = 10, n_jobs=-1, scoring=scoring_met)\n",
    "randm.fit(X_train, y_train)\n",
    "\n",
    "print(\" Results from Random Search \" )\n",
    "print(\"The best estimator across ALL searched params:\", randm.best_estimator_)\n",
    "print(\"The best score across ALL searched params:\", randm.best_score_)\n",
    "print(\"The best parameters across ALL searched params:\", randm.best_params_)\n",
    "\n",
    "append_file(\"The best estimator across ALL searched params:\", randm.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "#print(rf.get_params())\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "    'n_estimators': [1,5,10,15, 30, 50, 100, 500]\n",
    "    #'max_features': max_features,\n",
    "    #'max_depth': max_depth,\n",
    "    #'min_samples_split': min_samples_split,\n",
    "    #'min_samples_leaf': min_samples_leaf,\n",
    "    #'bootstrap': bootstrap\n",
    "}\n",
    "print(random_grid)\n",
    "\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=0, random_state=42, n_jobs = -1, scoring= scoring_met)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(\" Results from Random Search \" )\n",
    "print(\"The best estimator across ALL searched params:\", rf_random.best_estimator_)\n",
    "print(\"The best score across ALL searched params:\", rf_random.best_score_)\n",
    "print(\"The best parameters across ALL searched params:\", rf_random.best_params_)\n",
    "\n",
    "append_file(\"The best estimator across ALL searched params:\", rf_random.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2bc78f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\100737197\\AppData\\Local\\Temp\\ipykernel_23752\\2316969482.py:95: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_with_summary = df.append(summary_stats)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Your data containing feature importances for each iteration\n",
    "feature_importance_arrays = [\n",
    "    (['Test_Identifier', 'Execution_Count', 'Test_Total', 'Failure_Count',\n",
    "       'Failure_Rate', 'Last_Failure_Age', 'Last_Failure', 'Last_Transition',\n",
    "       'Transition_Count', '#Files_Changed', '#Lines_Inserted',\n",
    "       '#Lines_Deleted'],\n",
    "      [0.02500988, 0.20190792, 0.01041227, 0.1698891 , 0.19521764,\n",
    "       0.25818243, 0.00038318, 0.04366382, 0.06764993, 0.00713676,\n",
    "       0.01067264, 0.00987443]),\n",
    "    (['Test_Identifier', 'Execution_Count', 'Test_Total', 'Failure_Count',\n",
    "       'Failure_Rate', 'Last_Failure_Age', 'Last_Failure', 'Last_Transition',\n",
    "       'Transition_Count', '#Files_Changed', '#Lines_Inserted',\n",
    "       '#Lines_Deleted'],\n",
    "      [0.05712784, 0.10517232, 0.04327134, 0.10289942, 0.0997868 ,\n",
    "       0.29095332, 0.00352092, 0.07603804, 0.09906978, 0.02477701,\n",
    "       0.04693882, 0.0504444 ]),\n",
    "    (['Test_Identifier', 'Execution_Count', 'Test_Total', 'Failure_Count',\n",
    "       'Failure_Rate', 'Last_Failure_Age', 'Last_Failure', 'Last_Transition',\n",
    "       'Transition_Count', '#Files_Changed', '#Lines_Inserted',\n",
    "       '#Lines_Deleted'],\n",
    "      [0.03058563, 0.05978955, 0.01539822, 0.05563607, 0.1593346 ,\n",
    "       0.44572055, 0.00153501, 0.1010972 , 0.07508298, 0.02460651,\n",
    "       0.01574372, 0.01546996]),\n",
    "    (['Test_Identifier', 'Execution_Count', 'Test_Total', 'Failure_Count',\n",
    "       'Failure_Rate', 'Last_Failure_Age', 'Last_Failure', 'Last_Transition',\n",
    "       'Transition_Count', '#Files_Changed', '#Lines_Inserted',\n",
    "       '#Lines_Deleted'],\n",
    "      [0.02916288, 0.15101606, 0.0127574 , 0.14690894, 0.07244524,\n",
    "       0.35410208, 0.01024934, 0.09161541, 0.052897  , 0.05268679,\n",
    "       0.01299857, 0.0131603 ]),\n",
    "    (['Test_Identifier', 'Execution_Count', 'Test_Total', 'Failure_Count',\n",
    "       'Failure_Rate', 'Last_Failure_Age', 'Last_Failure', 'Last_Transition',\n",
    "       'Transition_Count', '#Files_Changed', '#Lines_Inserted',\n",
    "       '#Lines_Deleted'],\n",
    "      [0.10332848, 0.1276529 , 0.1271086 , 0.06443742, 0.11070639,\n",
    "       0.09463355, 0.07586803, 0.07879157, 0.06507503, 0.04113233,\n",
    "       0.06103815, 0.05022756]),\n",
    "    (['Test_Identifier', 'Execution_Count', 'Test_Total', 'Failure_Count',\n",
    "       'Failure_Rate', 'Last_Failure_Age', 'Last_Failure', 'Last_Transition',\n",
    "       'Transition_Count', '#Files_Changed', '#Lines_Inserted',\n",
    "       '#Lines_Deleted'],\n",
    "      [0.04450297, 0.08673542, 0.0377941 , 0.07902402, 0.09795123,\n",
    "       0.33188024, 0.00219607, 0.08516723, 0.05171485, 0.10828819,\n",
    "       0.03768683, 0.03705886]),\n",
    "    (['Test_Identifier', 'Execution_Count', 'Test_Total', 'Failure_Count',\n",
    "       'Failure_Rate', 'Last_Failure_Age', 'Last_Failure', 'Last_Transition',\n",
    "       'Transition_Count', '#Files_Changed', '#Lines_Inserted',\n",
    "       '#Lines_Deleted'],\n",
    "      [0.06267746, 0.1182618 , 0.03112703, 0.06238602, 0.09122182,\n",
    "       0.35002522, 0.00119146, 0.07765202, 0.06904928, 0.07321066,\n",
    "       0.03163351, 0.03156372]),\n",
    "    (['Test_Identifier', 'Execution_Count', 'Test_Total', 'Failure_Count',\n",
    "       'Failure_Rate', 'Last_Failure_Age', 'Last_Failure', 'Last_Transition',\n",
    "       'Transition_Count', '#Files_Changed', '#Lines_Inserted',\n",
    "       '#Lines_Deleted'],\n",
    "      [0.05315781, 0.17810726, 0.09522521, 0.12253971, 0.1030226 ,\n",
    "       0.05982357, 0.00559623, 0.05875813, 0.1020212 , 0.02448176,\n",
    "       0.09528918, 0.10197735]),\n",
    "    (['Test_Identifier', 'Execution_Count', 'Test_Total', 'Failure_Count',\n",
    "       'Failure_Rate', 'Last_Failure_Age', 'Last_Failure', 'Last_Transition',\n",
    "       'Transition_Count', '#Files_Changed', '#Lines_Inserted',\n",
    "       '#Lines_Deleted'],\n",
    "      [0.06029066, 0.10501026, 0.09023907, 0.09954604, 0.1600401 ,\n",
    "       0.09525006, 0.01066767, 0.05814674, 0.0957752 , 0.0436333 ,\n",
    "       0.09089564, 0.09050526]),\n",
    "    (['Test_Identifier', 'Execution_Count', 'Test_Total', 'Failure_Count',\n",
    "       'Failure_Rate', 'Last_Failure_Age', 'Last_Failure', 'Last_Transition',\n",
    "       'Transition_Count', '#Files_Changed', '#Lines_Inserted',\n",
    "       '#Lines_Deleted'],\n",
    "      [0.04590612, 0.09906415, 0.0649924 , 0.12001517, 0.23376228,\n",
    "       0.10501343, 0.02098082, 0.05130679, 0.09054504, 0.02937299,\n",
    "       0.07200195, 0.06703885])\n",
    "    # Add the data for the other 9 iterations here\n",
    "]\n",
    "\n",
    "# Create a dictionary to store the data\n",
    "data_dict = {}\n",
    "\n",
    "# Iterate through the feature importance arrays and populate the data dictionary\n",
    "for feature_names, importances in feature_importance_arrays:\n",
    "    for feature_name, importance in zip(feature_names, importances):\n",
    "        if feature_name not in data_dict:\n",
    "            data_dict[feature_name] = []\n",
    "        data_dict[feature_name].append(importance)\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Calculate mean, max, and min for each feature\n",
    "summary_stats = df.agg(['mean', 'max', 'min']).T.rename(columns={'mean': 'Mean', 'max': 'Max', 'min': 'Min'})\n",
    "\n",
    "# Save the DataFrame to a CSV file with summary statistics\n",
    "df_with_summary = df.append(summary_stats)\n",
    "summary_stats.to_csv('feature_importances_summary.csv', index=False)\n",
    "df_with_summary.to_csv('feature_importances_with_summary.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d632ab3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Identifier</th>\n",
       "      <th>Execution_Count</th>\n",
       "      <th>Test_Total</th>\n",
       "      <th>Failure_Count</th>\n",
       "      <th>Failure_Rate</th>\n",
       "      <th>Last_Failure_Age</th>\n",
       "      <th>Last_Failure</th>\n",
       "      <th>Last_Transition</th>\n",
       "      <th>Transition_Count</th>\n",
       "      <th>#Files_Changed</th>\n",
       "      <th>#Lines_Inserted</th>\n",
       "      <th>#Lines_Deleted</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025010</td>\n",
       "      <td>0.201908</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.169889</td>\n",
       "      <td>0.195218</td>\n",
       "      <td>0.258182</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.043664</td>\n",
       "      <td>0.067650</td>\n",
       "      <td>0.007137</td>\n",
       "      <td>0.010673</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057128</td>\n",
       "      <td>0.105172</td>\n",
       "      <td>0.043271</td>\n",
       "      <td>0.102899</td>\n",
       "      <td>0.099787</td>\n",
       "      <td>0.290953</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.076038</td>\n",
       "      <td>0.099070</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.046939</td>\n",
       "      <td>0.050444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030586</td>\n",
       "      <td>0.059790</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>0.055636</td>\n",
       "      <td>0.159335</td>\n",
       "      <td>0.445721</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.101097</td>\n",
       "      <td>0.075083</td>\n",
       "      <td>0.024607</td>\n",
       "      <td>0.015744</td>\n",
       "      <td>0.015470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029163</td>\n",
       "      <td>0.151016</td>\n",
       "      <td>0.012757</td>\n",
       "      <td>0.146909</td>\n",
       "      <td>0.072445</td>\n",
       "      <td>0.354102</td>\n",
       "      <td>0.010249</td>\n",
       "      <td>0.091615</td>\n",
       "      <td>0.052897</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.012999</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.103328</td>\n",
       "      <td>0.127653</td>\n",
       "      <td>0.127109</td>\n",
       "      <td>0.064437</td>\n",
       "      <td>0.110706</td>\n",
       "      <td>0.094634</td>\n",
       "      <td>0.075868</td>\n",
       "      <td>0.078792</td>\n",
       "      <td>0.065075</td>\n",
       "      <td>0.041132</td>\n",
       "      <td>0.061038</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.044503</td>\n",
       "      <td>0.086735</td>\n",
       "      <td>0.037794</td>\n",
       "      <td>0.079024</td>\n",
       "      <td>0.097951</td>\n",
       "      <td>0.331880</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.085167</td>\n",
       "      <td>0.051715</td>\n",
       "      <td>0.108288</td>\n",
       "      <td>0.037687</td>\n",
       "      <td>0.037059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.062677</td>\n",
       "      <td>0.118262</td>\n",
       "      <td>0.031127</td>\n",
       "      <td>0.062386</td>\n",
       "      <td>0.091222</td>\n",
       "      <td>0.350025</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.077652</td>\n",
       "      <td>0.069049</td>\n",
       "      <td>0.073211</td>\n",
       "      <td>0.031634</td>\n",
       "      <td>0.031564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.053158</td>\n",
       "      <td>0.178107</td>\n",
       "      <td>0.095225</td>\n",
       "      <td>0.122540</td>\n",
       "      <td>0.103023</td>\n",
       "      <td>0.059824</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.058758</td>\n",
       "      <td>0.102021</td>\n",
       "      <td>0.024482</td>\n",
       "      <td>0.095289</td>\n",
       "      <td>0.101977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.060291</td>\n",
       "      <td>0.105010</td>\n",
       "      <td>0.090239</td>\n",
       "      <td>0.099546</td>\n",
       "      <td>0.160040</td>\n",
       "      <td>0.095250</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.058147</td>\n",
       "      <td>0.095775</td>\n",
       "      <td>0.043633</td>\n",
       "      <td>0.090896</td>\n",
       "      <td>0.090505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.045906</td>\n",
       "      <td>0.099064</td>\n",
       "      <td>0.064992</td>\n",
       "      <td>0.120015</td>\n",
       "      <td>0.233762</td>\n",
       "      <td>0.105013</td>\n",
       "      <td>0.020981</td>\n",
       "      <td>0.051307</td>\n",
       "      <td>0.090545</td>\n",
       "      <td>0.029373</td>\n",
       "      <td>0.072002</td>\n",
       "      <td>0.067039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Identifier</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051175</td>\n",
       "      <td>0.103328</td>\n",
       "      <td>0.025010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Execution_Count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123272</td>\n",
       "      <td>0.201908</td>\n",
       "      <td>0.059790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Total</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052833</td>\n",
       "      <td>0.127109</td>\n",
       "      <td>0.010412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Failure_Count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102328</td>\n",
       "      <td>0.169889</td>\n",
       "      <td>0.055636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Failure_Rate</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.132349</td>\n",
       "      <td>0.233762</td>\n",
       "      <td>0.072445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last_Failure_Age</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.238558</td>\n",
       "      <td>0.445721</td>\n",
       "      <td>0.059824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last_Failure</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013219</td>\n",
       "      <td>0.075868</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last_Transition</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.072224</td>\n",
       "      <td>0.101097</td>\n",
       "      <td>0.043664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transition_Count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076888</td>\n",
       "      <td>0.102021</td>\n",
       "      <td>0.051715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Files_Changed</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042933</td>\n",
       "      <td>0.108288</td>\n",
       "      <td>0.007137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Lines_Inserted</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047490</td>\n",
       "      <td>0.095289</td>\n",
       "      <td>0.010673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Lines_Deleted</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046732</td>\n",
       "      <td>0.101977</td>\n",
       "      <td>0.009874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Test_Identifier  Execution_Count  Test_Total  Failure_Count  \\\n",
       "0                        0.025010         0.201908    0.010412       0.169889   \n",
       "1                        0.057128         0.105172    0.043271       0.102899   \n",
       "2                        0.030586         0.059790    0.015398       0.055636   \n",
       "3                        0.029163         0.151016    0.012757       0.146909   \n",
       "4                        0.103328         0.127653    0.127109       0.064437   \n",
       "5                        0.044503         0.086735    0.037794       0.079024   \n",
       "6                        0.062677         0.118262    0.031127       0.062386   \n",
       "7                        0.053158         0.178107    0.095225       0.122540   \n",
       "8                        0.060291         0.105010    0.090239       0.099546   \n",
       "9                        0.045906         0.099064    0.064992       0.120015   \n",
       "Test_Identifier               NaN              NaN         NaN            NaN   \n",
       "Execution_Count               NaN              NaN         NaN            NaN   \n",
       "Test_Total                    NaN              NaN         NaN            NaN   \n",
       "Failure_Count                 NaN              NaN         NaN            NaN   \n",
       "Failure_Rate                  NaN              NaN         NaN            NaN   \n",
       "Last_Failure_Age              NaN              NaN         NaN            NaN   \n",
       "Last_Failure                  NaN              NaN         NaN            NaN   \n",
       "Last_Transition               NaN              NaN         NaN            NaN   \n",
       "Transition_Count              NaN              NaN         NaN            NaN   \n",
       "#Files_Changed                NaN              NaN         NaN            NaN   \n",
       "#Lines_Inserted               NaN              NaN         NaN            NaN   \n",
       "#Lines_Deleted                NaN              NaN         NaN            NaN   \n",
       "\n",
       "                  Failure_Rate  Last_Failure_Age  Last_Failure  \\\n",
       "0                     0.195218          0.258182      0.000383   \n",
       "1                     0.099787          0.290953      0.003521   \n",
       "2                     0.159335          0.445721      0.001535   \n",
       "3                     0.072445          0.354102      0.010249   \n",
       "4                     0.110706          0.094634      0.075868   \n",
       "5                     0.097951          0.331880      0.002196   \n",
       "6                     0.091222          0.350025      0.001191   \n",
       "7                     0.103023          0.059824      0.005596   \n",
       "8                     0.160040          0.095250      0.010668   \n",
       "9                     0.233762          0.105013      0.020981   \n",
       "Test_Identifier            NaN               NaN           NaN   \n",
       "Execution_Count            NaN               NaN           NaN   \n",
       "Test_Total                 NaN               NaN           NaN   \n",
       "Failure_Count              NaN               NaN           NaN   \n",
       "Failure_Rate               NaN               NaN           NaN   \n",
       "Last_Failure_Age           NaN               NaN           NaN   \n",
       "Last_Failure               NaN               NaN           NaN   \n",
       "Last_Transition            NaN               NaN           NaN   \n",
       "Transition_Count           NaN               NaN           NaN   \n",
       "#Files_Changed             NaN               NaN           NaN   \n",
       "#Lines_Inserted            NaN               NaN           NaN   \n",
       "#Lines_Deleted             NaN               NaN           NaN   \n",
       "\n",
       "                  Last_Transition  Transition_Count  #Files_Changed  \\\n",
       "0                        0.043664          0.067650        0.007137   \n",
       "1                        0.076038          0.099070        0.024777   \n",
       "2                        0.101097          0.075083        0.024607   \n",
       "3                        0.091615          0.052897        0.052687   \n",
       "4                        0.078792          0.065075        0.041132   \n",
       "5                        0.085167          0.051715        0.108288   \n",
       "6                        0.077652          0.069049        0.073211   \n",
       "7                        0.058758          0.102021        0.024482   \n",
       "8                        0.058147          0.095775        0.043633   \n",
       "9                        0.051307          0.090545        0.029373   \n",
       "Test_Identifier               NaN               NaN             NaN   \n",
       "Execution_Count               NaN               NaN             NaN   \n",
       "Test_Total                    NaN               NaN             NaN   \n",
       "Failure_Count                 NaN               NaN             NaN   \n",
       "Failure_Rate                  NaN               NaN             NaN   \n",
       "Last_Failure_Age              NaN               NaN             NaN   \n",
       "Last_Failure                  NaN               NaN             NaN   \n",
       "Last_Transition               NaN               NaN             NaN   \n",
       "Transition_Count              NaN               NaN             NaN   \n",
       "#Files_Changed                NaN               NaN             NaN   \n",
       "#Lines_Inserted               NaN               NaN             NaN   \n",
       "#Lines_Deleted                NaN               NaN             NaN   \n",
       "\n",
       "                  #Lines_Inserted  #Lines_Deleted      Mean       Max  \\\n",
       "0                        0.010673        0.009874       NaN       NaN   \n",
       "1                        0.046939        0.050444       NaN       NaN   \n",
       "2                        0.015744        0.015470       NaN       NaN   \n",
       "3                        0.012999        0.013160       NaN       NaN   \n",
       "4                        0.061038        0.050228       NaN       NaN   \n",
       "5                        0.037687        0.037059       NaN       NaN   \n",
       "6                        0.031634        0.031564       NaN       NaN   \n",
       "7                        0.095289        0.101977       NaN       NaN   \n",
       "8                        0.090896        0.090505       NaN       NaN   \n",
       "9                        0.072002        0.067039       NaN       NaN   \n",
       "Test_Identifier               NaN             NaN  0.051175  0.103328   \n",
       "Execution_Count               NaN             NaN  0.123272  0.201908   \n",
       "Test_Total                    NaN             NaN  0.052833  0.127109   \n",
       "Failure_Count                 NaN             NaN  0.102328  0.169889   \n",
       "Failure_Rate                  NaN             NaN  0.132349  0.233762   \n",
       "Last_Failure_Age              NaN             NaN  0.238558  0.445721   \n",
       "Last_Failure                  NaN             NaN  0.013219  0.075868   \n",
       "Last_Transition               NaN             NaN  0.072224  0.101097   \n",
       "Transition_Count              NaN             NaN  0.076888  0.102021   \n",
       "#Files_Changed                NaN             NaN  0.042933  0.108288   \n",
       "#Lines_Inserted               NaN             NaN  0.047490  0.095289   \n",
       "#Lines_Deleted                NaN             NaN  0.046732  0.101977   \n",
       "\n",
       "                       Min  \n",
       "0                      NaN  \n",
       "1                      NaN  \n",
       "2                      NaN  \n",
       "3                      NaN  \n",
       "4                      NaN  \n",
       "5                      NaN  \n",
       "6                      NaN  \n",
       "7                      NaN  \n",
       "8                      NaN  \n",
       "9                      NaN  \n",
       "Test_Identifier   0.025010  \n",
       "Execution_Count   0.059790  \n",
       "Test_Total        0.010412  \n",
       "Failure_Count     0.055636  \n",
       "Failure_Rate      0.072445  \n",
       "Last_Failure_Age  0.059824  \n",
       "Last_Failure      0.000383  \n",
       "Last_Transition   0.043664  \n",
       "Transition_Count  0.051715  \n",
       "#Files_Changed    0.007137  \n",
       "#Lines_Inserted   0.010673  \n",
       "#Lines_Deleted    0.009874  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "acdbd7b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Statistic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Statistic'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m df_with_summary \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_importances_with_summary.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Extract mean, max, and min values into separate DataFrames\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m mean_values \u001b[38;5;241m=\u001b[39m df_with_summary[\u001b[43mdf_with_summary\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStatistic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m max_values \u001b[38;5;241m=\u001b[39m df_with_summary[df_with_summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatistic\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m min_values \u001b[38;5;241m=\u001b[39m df_with_summary[df_with_summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatistic\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Statistic'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the DataFrame with summary statistics\n",
    "df_with_summary = pd.read_csv('feature_importances_with_summary.csv')\n",
    "\n",
    "# Extract mean, max, and min values into separate DataFrames\n",
    "mean_values = df_with_summary[df_with_summary['Statistic'] == 'Mean']\n",
    "max_values = df_with_summary[df_with_summary['Statistic'] == 'Max']\n",
    "min_values = df_with_summary[df_with_summary['Statistic'] == 'Min']\n",
    "\n",
    "# Combine the three DataFrames\n",
    "summary_data = pd.concat([mean_values, max_values, min_values], ignore_index=True)\n",
    "\n",
    "# Create a box plot using Seaborn\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.boxplot(x=\"Statistic\", y=\"Value\", data=summary_data, hue=\"Feature\", palette=\"Set3\")\n",
    "plt.title(\"Box Plot of Summary Statistics for Feature Importances\")\n",
    "plt.xlabel(\"Statistic\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "02d0a79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test_Identifier</th>\n",
       "      <td>0.051175</td>\n",
       "      <td>0.103328</td>\n",
       "      <td>0.025010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Execution_Count</th>\n",
       "      <td>0.123272</td>\n",
       "      <td>0.201908</td>\n",
       "      <td>0.059790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test_Total</th>\n",
       "      <td>0.052833</td>\n",
       "      <td>0.127109</td>\n",
       "      <td>0.010412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Failure_Count</th>\n",
       "      <td>0.102328</td>\n",
       "      <td>0.169889</td>\n",
       "      <td>0.055636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Failure_Rate</th>\n",
       "      <td>0.132349</td>\n",
       "      <td>0.233762</td>\n",
       "      <td>0.072445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last_Failure_Age</th>\n",
       "      <td>0.238558</td>\n",
       "      <td>0.445721</td>\n",
       "      <td>0.059824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last_Failure</th>\n",
       "      <td>0.013219</td>\n",
       "      <td>0.075868</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last_Transition</th>\n",
       "      <td>0.072224</td>\n",
       "      <td>0.101097</td>\n",
       "      <td>0.043664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transition_Count</th>\n",
       "      <td>0.076888</td>\n",
       "      <td>0.102021</td>\n",
       "      <td>0.051715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Files_Changed</th>\n",
       "      <td>0.042933</td>\n",
       "      <td>0.108288</td>\n",
       "      <td>0.007137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Lines_Inserted</th>\n",
       "      <td>0.047490</td>\n",
       "      <td>0.095289</td>\n",
       "      <td>0.010673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#Lines_Deleted</th>\n",
       "      <td>0.046732</td>\n",
       "      <td>0.101977</td>\n",
       "      <td>0.009874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Mean       Max       Min\n",
       "Test_Identifier   0.051175  0.103328  0.025010\n",
       "Execution_Count   0.123272  0.201908  0.059790\n",
       "Test_Total        0.052833  0.127109  0.010412\n",
       "Failure_Count     0.102328  0.169889  0.055636\n",
       "Failure_Rate      0.132349  0.233762  0.072445\n",
       "Last_Failure_Age  0.238558  0.445721  0.059824\n",
       "Last_Failure      0.013219  0.075868  0.000383\n",
       "Last_Transition   0.072224  0.101097  0.043664\n",
       "Transition_Count  0.076888  0.102021  0.051715\n",
       "#Files_Changed    0.042933  0.108288  0.007137\n",
       "#Lines_Inserted   0.047490  0.095289  0.010673\n",
       "#Lines_Deleted    0.046732  0.101977  0.009874"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bad1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
